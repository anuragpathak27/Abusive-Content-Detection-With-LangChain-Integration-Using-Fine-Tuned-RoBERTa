# Abusive-Content-Detection-With-LangChain-Integration-Using-Fine-Tuned-RoBERTa

## Overview
This repository contains the **Google Colab code** for the research paper **"Abusive Content Detection with LangChain Integration Using Fine-Tuned RoBERTa"**, presented at **14th IEEE International Conference on CSNT 2025**. The project focuses on detecting abusive content in text using a fine-tuned **RoBERTa model**, integrated with **LangChain** for improved text processing.

## Features
- Fine-tuned **RoBERTa** model for abusive content detection.
- **LangChain** integration for efficient text processing.
- **Google Colab**-based implementation.

## Dataset
The model is trained on the **Hate Speech and Offensive Language Dataset**, available on Kaggle:  
ðŸ”— [Dataset Link](https://www.kaggle.com/datasets/mrmorj/hate-speech-and-offensive-language-dataset)

## Repository Contents
- **`Abusive_Content_Detection.ipynb`** â€“ The Colab notebook with the complete implementation.

## Installation & Usage
### Run the Colab Notebook
1. Clone this repository:
   ```bash
   git clone https://github.com/anuragpathak27/Abusive-Content-Detection-With-LangChain-Integration-Using-Fine-Tuned-RoBERTa.git
